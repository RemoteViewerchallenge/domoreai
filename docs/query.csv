{
"SavedQuery": [
	{
		"id" : "cmjh2jjtl000610y2rqsxpvyg",
		"name" : "create_master_models_table",
		"query" : "CREATE TABLE \"my_free_models\" (model_id TEXT NOT NULL,provider_id UUID NOT NULL,data_source TEXT,name TEXT,context_window INT DEFAULT 4096,max_output_tokens INT DEFAULT 4096,parameter_size_B REAL DEFAULT 0.0,has_vision BOOLEAN DEFAULT FALSE,is_coding_model BOOLEAN DEFAULT FALSE,is_reasoning_model BOOLEAN DEFAULT FALSE,supports_rag BOOLEAN DEFAULT FALSE,supports_json BOOLEAN DEFAULT FALSE,supports_tools BOOLEAN DEFAULT FALSE,is_uncensored BOOLEAN DEFAULT FALSE,underlying_provider TEXT,is_free BOOLEAN DEFAULT FALSE,cost NUMERIC DEFAULT 0.0,supported_parameters JSONB DEFAULT '[]'::jsonb,PRIMARY KEY (model_id, provider_id));",
		"targetTable" : "my_free_models",
		"updatedAt" : "2025-11-27T14:00:00.000Z"
	},
	{
		"id" : "cmjh2kgji000710y2p4h2df80",
		"name" : "populate_master_models_table",
		"query" : "WITH ProviderIDs AS (SELECT id, type FROM \"ProviderConfig\"),OpenRouter_Models AS (SELECT TRIM(t1.canonical_slug) AS model_id,(SELECT id FROM ProviderIDs WHERE type = 'openrouter') AS provider_id,'openrouter' AS data_source,t1.name,COALESCE(t1.context_length::int, 4096) AS context_window,COALESCE((t1.top_provider::jsonb ->> 'max_completion_tokens')::int, 4096) AS max_output_tokens,COALESCE((regexp_match(t1.description, '(\\d+(\\.\\d+)?)\\s?B(?=\\s?parameter|expert)'))[1]::REAL, 0.0) AS parameter_size_B,t1.description ~* 'vision|image|multimodal|visual|vl-' AS has_vision,t1.description ~* 'code|coder|solidity|coding|swe|patch' AS is_coding_model,t1.description ~* 'reasoning|chain-of-thought|CoT|math|expert|thinking|logic' AS is_reasoning_model,t1.description ~* 'search|RAG|retrieval' AS supports_rag,t1.supported_parameters::jsonb @> '[\"response_format\"]'::jsonb OR t1.supported_parameters::jsonb @> '[\"structured_outputs\"]'::jsonb AS supports_json,t1.supported_parameters::jsonb @> '[\"tools\"]'::jsonb OR t1.supported_parameters::jsonb @> '[\"tool_choice\"]'::jsonb AS supports_tools,(t1.top_provider::jsonb ->> 'is_moderated')::boolean IS FALSE AS is_uncensored,(regexp_match(TRIM(t1.canonical_slug), '^([^\/]+)'))[1] AS underlying_provider,TRUE AS is_free,0.0 AS cost,t1.supported_parameters::jsonb AS supported_parameters FROM \"orouter\" t1 WHERE (t1.pricing::jsonb ->> 'prompt')::numeric = 0 OR t1.canonical_slug LIKE '%:free'),TogetherAI_Models AS (SELECT TRIM(t1.model_id) AS model_id,(SELECT id FROM ProviderIDs WHERE type = 'togetherai') AS provider_id,'together' AS data_source,t1.model_id AS name,COALESCE(t1.context_length::int, 8192) AS context_window,4096 AS max_output_tokens,0.0 AS parameter_size_B,t1.model_id ~* 'vision|image' AS has_vision,t1.model_id ~* 'code|coder' AS is_coding_model,FALSE AS is_reasoning_model,FALSE AS supports_rag,TRUE AS supports_json,FALSE AS supports_tools,FALSE AS is_uncensored,'together' AS underlying_provider,TRUE AS is_free,0.0 AS cost,t1.config::jsonb AS supported_parameters FROM \"tgthr\" t1 WHERE (t1.pricing::jsonb ->> 'input')::numeric = 0),GoogleAI_Models AS (SELECT TRIM(t1.name) AS model_id,(SELECT id FROM ProviderIDs WHERE type = 'google') AS provider_id,'google' AS data_source,t1.displayName AS name,COALESCE(t1.inputTokenLimit::int, 1048576) AS context_window,COALESCE(t1.outputTokenLimit::int, 8192) AS max_output_tokens,0.0 AS parameter_size_B,t1.supportedGenerationMethods ~* 'embed|vision|image' AS has_vision,t1.description ~* 'code' AS is_coding_model,t1.description ~* 'thinking|reasoning' OR t1.thinking = 'true' AS is_reasoning_model,TRUE AS supports_rag,TRUE AS supports_json,TRUE AS supports_tools,FALSE AS is_uncensored,'google' AS underlying_provider,TRUE AS is_free,0.0 AS cost,'[]'::jsonb AS supported_parameters FROM \"googleAI\" t1),OpenAI_Models AS (SELECT t1.model_id AS model_id,(SELECT id FROM ProviderIDs WHERE type = 'openai') AS provider_id,'openai' AS data_source,t1.model_id AS name,128000 AS context_window,4096 AS max_output_tokens,0.0 AS parameter_size_B,t1.model_id ~* 'gpt-4o|vision' AS has_vision,t1.model_id ~* 'code' AS is_coding_model,t1.model_id ~* 'o1|reasoning' AS is_reasoning_model,TRUE AS supports_rag,TRUE AS supports_json,TRUE AS supports_tools,FALSE AS is_uncensored,'openai' AS underlying_provider,FALSE AS is_free,1.0 AS cost,'[]'::jsonb AS supported_parameters FROM \"openai\" t1),Mistral_Models AS (SELECT t1.model_id AS model_id,(SELECT id FROM ProviderIDs WHERE type = 'mistral') AS provider_id,'mistral' AS data_source,t1.model_id AS name,COALESCE(t1.max_context_length::int, 32000) AS context_window,4096 AS max_output_tokens,0.0 AS parameter_size_B,t1.capabilities::jsonb ->> 'vision' = 'true' AS has_vision,t1.model_id ~* 'code|codestral' AS is_coding_model,FALSE AS is_reasoning_model,FALSE AS supports_rag,t1.capabilities::jsonb ->> 'function_calling' = 'true' AS supports_json,t1.capabilities::jsonb ->> 'function_calling' = 'true' AS supports_tools,t1.model_id ~* 'uncensored' AS is_uncensored,'mistral' AS underlying_provider,FALSE AS is_free,1.0 AS cost,'[]'::jsonb AS supported_parameters FROM \"mist\" t1),Ollama_Models AS (SELECT t1.model AS model_id,(SELECT id FROM ProviderIDs WHERE type = 'ollama') AS provider_id,'ollama' AS data_source,t1.name AS name,4096 AS context_window,4096 AS max_output_tokens,COALESCE((regexp_match(t1.size, '(\\d+(\.\d+)?)\s?B'))[1]::REAL, 0.0) AS parameter_size_B,t1.details::text ~* 'vision' AS has_vision,t1.model ~* 'code' AS is_coding_model,FALSE AS is_reasoning_model,FALSE AS supports_rag,TRUE AS supports_json,FALSE AS supports_tools,TRUE AS is_uncensored,'ollama' AS underlying_provider,TRUE AS is_free,0.0 AS cost,'[]'::jsonb AS supported_parameters FROM \"local1\" t1)\nINSERT INTO \"my_free_models\" (model_id, provider_id, data_source, name, context_window, max_output_tokens, parameter_size_B,has_vision, is_coding_model, is_reasoning_model, supports_rag, supports_json, supports_tools,is_uncensored, underlying_provider, is_free, cost, supported_parameters)SELECT * FROM OpenRouter_Models\nUNION ALL SELECT * FROM TogetherAI_Models\nUNION ALL SELECT * FROM GoogleAI_Models\nUNION ALL SELECT * FROM OpenAI_Models\nUNION ALL SELECT * FROM Mistral_Models\nUNION ALL SELECT * FROM Ollama_Models\nON CONFLICT (model_id, provider_id) DO NOTHING;",
		"targetTable" : "my_free_models",
		"updatedAt" : "2025-11-27T14:00:00.000Z"
	},
	{
		"id" : "cmjh2lijs000910y2p4h2df81",
		"name" : "create_capability_inference_table",
		"query" : "CREATE TABLE \"model_capability_inference\" (model_id TEXT NOT NULL,provider_id UUID NOT NULL,is_reasoning_provider BOOLEAN DEFAULT FALSE,is_vision_provider BOOLEAN DEFAULT FALSE,multilingual_language_count INT DEFAULT 0,PRIMARY KEY (model_id, provider_id));",
		"targetTable" : "model_capability_inference",
		"updatedAt" : "2025-11-27T14:00:00.000Z"
	},
	{
		"id" : "cmjh2lijs000a10y2p4h2df82",
		"name" : "populate_capability_inference_table",
		"query" : "INSERT INTO \"model_capability_inference\" (model_id, provider_id, is_reasoning_provider, is_vision_provider, multilingual_language_count)\nSELECT\n    T1.model_id,\n    T1.provider_id,\n    CASE\n        WHEN T1.data_source = 'google' AND T1.name ~* 'Gemini 3|Gemini 2\\.5 Pro' THEN TRUE\n        WHEN T1.data_source = 'openrouter' AND (T1.underlying_provider ~* 'deepseek|perplexity|grok' OR T1.model_id ~* 'reasoning|thinking') THEN TRUE\n        WHEN T1.data_source = 'mistral' AND T1.name ~* 'Magistral|Mixtral 8x22B' THEN TRUE\n        ELSE FALSE\n    END AS is_reasoning_provider,\n    CASE\n        WHEN T1.data_source = 'google' AND T1.name ~* 'Gemini' THEN TRUE\n        WHEN T1.data_source = 'openrouter' AND T1.underlying_provider ~* 'llama-4|claude|qwen-vl|phi-4' THEN TRUE\n        WHEN T1.data_source = 'openai' AND T1.name ~* 'gpt-4o' THEN TRUE\n        ELSE FALSE\n    END AS is_vision_provider,\n    COALESCE(\n        (SELECT (regexp_match(t2.description, 'over (\\d+)\\s?languages'))[1]::INT FROM \"orouter\" t2 WHERE TRIM(t2.canonical_slug) = T1.model_id),\n        CASE\n            WHEN T1.data_source IN ('mistral', 'google') THEN 100\n            WHEN T1.data_source = 'openrouter' AND T1.underlying_provider ~* 'llama' THEN 8\n            WHEN T1.data_source = 'openai' THEN 50\n            ELSE 1\n        END\n    ) AS multilingual_language_count\nFROM \"my_free_models\" T1\nON CONFLICT (model_id, provider_id) DO NOTHING;",
		"targetTable" : "model_capability_inference",
		"updatedAt" : "2025-11-27T14:00:00.000Z"
	}
]
}